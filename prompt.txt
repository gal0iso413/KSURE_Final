## **Final Revised Plan: XGBoost Risk Prediction Model Development**

### IMPORTANT: DONT change any name be yourself. Try to leave as it was.
### IMPORTANT: KOREAN FONT is needed for visualization. Don't remove that part.

### **Phase 1: Foundation & Understanding**

**Step 1: Simple Baseline Model**
- Load data from 1_Dataset.py output
- Basic data exploration (shape, missing values, target distribution)
- Train and compare three models on the same split: XGBoost, MLP, RandomForest
- Use simple train/test split (80/20) without considering dates
- Save per-model metrics, plots, and model artifacts
- *Goal: Establish working pipeline and baseline performance across diverse model families*

**Step 2: Basic Evaluation Framework**
- Implement proper multi-class evaluation metrics
- Create confusion matrix visualization
- Document baseline performance for comparison
- *Goal: Understand current model performance*

**Step 3: Comprehensive Exploratory Data Analysis (EDA)**
- **Data Quality Analysis**: Missing patterns, outliers, data types
- **Target Variable Analysis**: Class distribution over time
- **Feature Relationships**: Correlation analysis, feature distributions by target class
- *Goal: Deep understanding of data characteristics to inform all subsequent decisions*

### **Phase 2: Feature Engineering & Selection**

**Step 4: Feature Refinement and Selection**
- **Multicollinearity Removal**: Remove highly correlated features (>0.9-0.95 threshold)
- **Variance Threshold**: Remove near-zero variance features (<0.001)
- **Missing Value Threshold**: Remove features with >50% missing values
- **Stability-Based Selection**: For each target, run repeated 80/20 random splits and compute permutation importance on the holdout; in each run keep the smallest set reaching 90% cumulative importance (min 25, max 120). Compute feature stability (share of runs selected) per target. Final feature set is the UNION of features with stability ≥ threshold (e.g., 0.6) for ANY target. Save both full list and a variant without regime-proxy features for later comparison.
- *Goal: Robust, multi-target-aware selection without arbitrary cutoffs*

### **Phase 3: Temporal Validation Strategy**

**Step 5: Unified Temporal Validation**
- **Approach 1**: Random Split (shuffle=True) - Performance baseline ignoring temporal characteristics
- **Approach 2**: Stratified Random Split (shuffle=True, stratify=y) - Baseline with class balance
- **Approach 3**: Simple Temporal Holdout (shuffle=False) - Basic temporal validation (past vs future)
- **Approach 4**: Expanding Window CV - Evaluates stability as more data accumulates over time
- **Approach 5**: Rolling Window CV - Evaluates adaptation to recent trends by discarding old data
- **Data Sorting**: Critical sorting by 보험청약일자 before temporal validation
- **Inconsistent Parameters**: Different split ratios and fold counts for all targets
- **Multi-Target Analysis**: Tested across risk_year1, risk_year2, risk_year3, risk_year4
- *Goal: Establish the most reliable temporal validation approach*

### **Phase 4: Class Imbalance Strategy**

**Step 6: Class Imbalance Strategy**
- **Apply to Optimized Features**: Use best feature set from Step 4 (27 features)
- **Use Rolling Window CV**: From Step 5 for temporal robustness
- **Phase 1 - Enhanced Evaluation**: Balanced Accuracy, Cohen's Kappa, Macro F1, High-Risk Recall, Classification Reports; per-fold class prevalence logging
- **Phase 2 - Algorithm-Level Reweighting**: Class-Balanced (Effective Number of Samples) weights; optional focal loss fallback; prior correction at inference
- **Phase 3 - Balanced Bagging Ensemble**: Train M submodels per fold with controlled undersampling of class 0 + class-balanced weights; average probabilities
- **Phase 4 - Calibration + Business Thresholds**: Per-class Platt calibration on temporal split; optimize thresholds in business priority order (3→2→1→0)
- **Phase 5 - Ordinal Alternative**: Train K−1 cumulative ordinal models; compare against multiclass ensemble
- **Phase 6 - Selection Policy**: Select best strategy per target (risk_year1-4) prioritizing high-risk recall with stability guard (mean F1 − std F1)
- **Temporal Integrity**: Preserve original temporal distribution; no synthetic sampling
- **Multi-Target Analysis**: Test across risk_year1-4 with varying class distributions
- **Business Focus**: Prioritize high-risk recall (classes 2-3) for business alignment
- *Goal: Address data imbalance with temporally robust validation and business-optimized thresholds*

### **Phase 5: Model Architecture Experiments**

**Step 7: Model Architecture Experiments**
- **Phase 1 - Unified vs. Individual Models**: Compare unified configuration (one shared configuration across all targets) vs. individual configurations (per-target configuration). Both use Step 6 handling so only architecture/config changes are compared.
- **Phase 2 - Two-Stage Cascade Model**: High-risk Gate (2/3 vs 0/1) + Specialist (2 vs 3) with calibrated thresholds
- **Use Optimized Features**: From Step 4 results
- **Use Rolling Window CV**: From Step 5 for temporal robustness
- **Ordinal Alternative**: From Step 6
- **Evaluation Metrics**: High-risk Recall (primary), F1-macro, Balanced Accuracy, Cohen's Kappa, High-risk PR-AUC, ECE, Stability (mean F1 − std F1)
- **Sparse Targets Handling**: Adapt window size/folds for very sparse targets to ensure valid folds
- **Efficient Training**: Reuse results from previous phases to avoid duplicate training
- *Goal: Find optimal model architecture with comprehensive optimal setup*

### **Phase 6: Model Optimization**

**Step 8: Hyperparameter Tuning with Optuna**
- Define search space based on selected architecture (Step 7)
- Use selected temporal validation strategy (Step 5)
- Optimize for high-risk recall
- **Use Two stage cascade**: From Step 7 results
- **Use Optimized Features**: From Step 4 results
- **Use Rolling Window CV**: From Step 5 results
- **Use Ordinal cumulative**: From Step 6 results
- *Goal: Find optimal model configuration*

### **Phase 7: Analysis & Interpretation**

**Step 9: Feature Importance & Interpretability**
- Generate SHAP values for selected architecture
- Provide business interpretations of feature importance
- Analyze temporal feature importance patterns
- **Use Final Model**: From Step 8 results
- *Goal: Provide explainable predictions*

**Step 10: Comprehensive Visualization**
- Create business-focused visualizations
- Temporal performance analysis
- Risk prediction patterns over time
- **Use Final Model**: From Step 8 results
- *Goal: Generate actionable insights*

### **Phase 8: Validation & Documentation**

**Step 11: Model Validation & Testing**
- Test across multiple periods using temporal CV
- Validate business assumptions
- Performance degradation analysis over time
- **Use Final Model**: From Step 8 results
- *Goal: Ensure production readiness*

**Step 12: Final Documentation & Deployment Prep**
- Document limitations and recommendations
- Model deployment specifications
- Monitoring and maintenance guidelines
- **Use Final Model**: From Step 8 results
- *Goal: Deliver production-ready model*

---

## **Key Strategic Decisions Made:**

### **Feature-First Approach:**
- **Rationale**: Optimal features are foundation for all subsequent steps
- **Strategy**: Feature engineering → Temporal validation → Imbalance → Architecture → Hyperparameters
- **Expected Outcome**: Each step builds on optimized foundation from previous steps

### **Temporal Focus:**
- **Priority**: Time series cross-validation and temporal model architectures
- **Business Alignment**: Credit risk prediction requires temporal stability
- **Validation**: Multiple time periods to ensure model robustness

### **Performance Targets:**
- **High-Risk Recall**: 2~3 is the most important risk
- **F1-Macro**: Maximize while maintaining high-risk performance
- **Temporal Stability**: Consistent performance across time periods