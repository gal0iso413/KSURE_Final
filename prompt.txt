## **Final Revised Plan: XGBoost Risk Prediction Model Development**

### IMPORTANT: DONT change any name be yourself. Try to leave as it was.
### IMPORTANT: KOREAN FONT is needed for visualization. Don't remove that part.

### **Phase 1: Foundation & Understanding**

**Step 1: Simple Baseline Model**
- Load data from 1_Dataset.py output
- Basic data exploration (shape, missing values, target distribution)
- Train and compare three models on the same split: XGBoost, MLP, RandomForest
- Use simple train/test split (80/20) without considering dates
- Save per-model metrics, plots, and model artifacts
- *Goal: Establish working pipeline and baseline performance across diverse model families*

**Step 2: Basic Evaluation Framework**
- Implement proper multi-class evaluation metrics
- Create confusion matrix visualization
- Document baseline performance for comparison
- *Goal: Understand current model performance*

**Step 3: Comprehensive Exploratory Data Analysis (EDA)**
- **Data Quality Analysis**: Missing patterns, outliers, data types
- **Target Variable Analysis**: Class distribution over time
- **Feature Relationships**: Correlation analysis, feature distributions by target class
- *Goal: Deep understanding of data characteristics to inform all subsequent decisions*

### **Phase 2: Feature Engineering & Selection**

**Step 4: Feature Refinement and Selection**
- **Multicollinearity Removal**: Remove highly correlated features (>0.9-0.95 threshold)
- **Variance Threshold**: Remove near-zero variance features (<0.001)
- **Missing Value Threshold**: Remove features with >50% missing values
- **Stability-Based Selection**: For each target, run repeated 80/20 random splits and compute permutation importance on the holdout; in each run keep the smallest set reaching 90% cumulative importance (min 25, max 120). Compute feature stability (share of runs selected) per target. Final feature set is the UNION of features with stability ≥ threshold (e.g., 0.6) for ANY target. Save both full list and a variant without regime-proxy features for later comparison.
- *Goal: Robust, multi-target-aware selection without arbitrary cutoffs*

### **Phase 3: Temporal Validation Strategy**

**Step 5: Unified Temporal Validation**
- **Approach 1**: Random Split (shuffle=True) - Performance baseline ignoring temporal characteristics
- **Approach 2**: Stratified Random Split (shuffle=True, stratify=y) - Baseline with class balance
- **Approach 3**: Simple Temporal Holdout (shuffle=False) - Basic temporal validation (past vs future)
- **Approach 4**: Expanding Window CV - Evaluates stability as more data accumulates over time
- **Approach 5**: Rolling Window CV - Evaluates adaptation to recent trends by discarding old data
- **Data Sorting**: Critical sorting by 보험청약일자 before temporal validation
- **Inconsistent Parameters**: Different split ratios and fold counts for all targets
- **Multi-Target Analysis**: Tested across risk_year1, risk_year2, risk_year3, risk_year4
- *Goal: Establish the most reliable temporal validation approach*

### **Phase 4: Class Imbalance Strategy (Simplified for Explainability)**

**Step 6: Class Imbalance Strategy**
- **Apply to Optimized Features**: Use best feature set from Step 4 (27 features)
- **Use Rolling Window CV**: From Step 5 for temporal robustness
- **Phase 1 - Algorithm-Level Reweighting**: Class-balanced sample weights (e.g., sklearn 'balanced'). Single XGBoost model; predictions via argmax.
- **Phase 2 - Calibration (Training-only)**: Calibrate probabilities (e.g., Platt/temperature) using only training data (held-out slice or OOF). Predictions via argmax. No threshold search.
- **Baselines**: Include an Original baseline (no imbalance handling, no calibration) for fair comparison.
- **Evaluation Layer**: Balanced Accuracy, Cohen's Kappa, Macro F1, High-Risk Recall, per-class metrics, classification reports; per-fold class prevalence logging.
- **Deferred (moved to later steps)**: Balanced bagging ensembles, business/ordinal thresholds, ordinal cumulative models.
- **Temporal Integrity**: Preserve original temporal distribution; no synthetic sampling
- **Multi-Target Analysis**: Test across risk_year1-4 with varying class distributions
- **Business Focus**: Prioritize high-risk recall (classes 2-3) for business alignment
- *Goal: Address data imbalance and probability reliability with a simple, explainable single-model pipeline*

### **Phase 5: Model Architecture Experiments**

**Step 7: Model Architecture Experiments (Two-Phase)**
- **Phase 1 - Unified vs Individual Models**: Compare a unified configuration (one shared model across all four targets using a `task_id` feature) versus individual configurations (one model per target). Both arms reuse Step 6 handling (class-balanced sample weights; optional training-only calibration) and are evaluated with the same rolling window folds.
- **Phase 2 - Best-of-Phase1 vs Ordinal Method (Interpretable)**: For each target, compare the winner from Phase 1 against an interpretable ordinal process (single regressor on labels {0,1,2,3} with class-balanced weights; three fixed cutpoints learned on training-only OOF). No test-time label usage.
- **Use Optimized Features**: From Step 4 results
- **Use Rolling Window CV**: From Step 5 for temporal robustness
- **Algorithm-Level Reweighting**: From Step 6
- **Evaluation Metrics**: High-risk Recall (primary), F1-macro, Balanced Accuracy, Cohen's Kappa, High-risk PR-AUC, ECE, Stability (mean F1 − std F1)
- **Sparse Targets Handling**: Adapt window size/folds for very sparse targets to ensure valid folds
- **Efficient Training**: Reuse results from previous phases to avoid duplicate training
- *Goal: Decide architecture (Unified vs Individual) and assess value of an interpretable ordinal alternative per target*

### **Phase 6: Model Optimization**

**Step 8: Hyperparameter Tuning with Optuna**
- Define search space based on selected architecture (Step 7)
- Use selected temporal validation strategy (Step 5)
- Optimize for high-risk recall
- **Use Individual model**: From Step 7 results
- **Use Optimized Features**: From Step 4 results
- **Use Rolling Window CV**: From Step 5 results
- **Use Ordinal cumulative**: From Step 6 results
- *Goal: Find optimal model configuration*

### **Phase 7: Analysis & Interpretation**

**Step 9: Feature Importance & Interpretability**
- Generate SHAP values for selected architecture
- Provide business interpretations of feature importance
- Analyze temporal feature importance patterns
- **Use Final Model**: From Step 8 results
- *Goal: Provide explainable predictions*

**Step 10: Comprehensive Visualization**
- Create business-focused visualizations
- Temporal performance analysis
- Risk prediction patterns over time
- **Use Final Model**: From Step 8 results
- *Goal: Generate actionable insights*

### **Phase 8: Validation & Documentation**

**Step 11: Model Validation & Testing**
- Test across multiple periods using temporal CV
- Validate business assumptions
- Performance degradation analysis over time
- **Use Final Model**: From Step 8 results
- *Goal: Ensure production readiness*

**Step 12: Final Documentation & Deployment Prep**
- Document limitations and recommendations
- Model deployment specifications
- Monitoring and maintenance guidelines
- **Use Final Model**: From Step 8 results
- *Goal: Deliver production-ready model*

---

## **Key Strategic Decisions Made:**

### **Feature-First Approach:**
- **Rationale**: Optimal features are foundation for all subsequent steps
- **Strategy**: Feature engineering → Temporal validation → Imbalance → Architecture → Hyperparameters
- **Expected Outcome**: Each step builds on optimized foundation from previous steps

### **Temporal Focus:**
- **Priority**: Time series cross-validation and temporal model architectures
- **Business Alignment**: Credit risk prediction requires temporal stability
- **Validation**: Multiple time periods to ensure model robustness

### **Performance Targets:**
- **High-Risk Recall**: 2~3 is the most important risk
- **F1-Macro**: Maximize while maintaining high-risk performance
- **Temporal Stability**: Consistent performance across time periods